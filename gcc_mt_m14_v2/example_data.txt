# Example Data for L3 M14.2: Incident Management & Blast Radius

## Production Incident Scenario

Timeline: 2025-01-15 14:30:00 IST
Incident: INC-20250115-143000
Priority: P0 (Critical)

14:30:00 - Tenant platinum-1 deploys new query with infinite loop
14:30:15 - Error rate spikes to 25% (250 errors/1000 queries)
14:30:30 - Error rate reaches 60% (600 errors/1000 queries)
14:30:40 - BlastRadiusDetector detects failing tenant (above 50% threshold)
14:30:45 - Circuit breaker records 1st failure
14:30:55 - Circuit breaker records 5th failure, transitions to OPEN state
14:30:56 - Tenant platinum-1 isolated, all traffic blocked
14:30:57 - PagerDuty alert sent to ops team
14:30:58 - Slack notification sent to #incidents channel
14:31:00 - Other 49 tenants continue normal operation
14:35:00 - Ops team identifies infinite loop query
14:40:00 - Query rolled back, error rate drops to 5%
14:41:55 - Circuit breaker transitions to HALF_OPEN (60-second timeout expired)
14:42:00 - Test query succeeds, circuit breaker transitions to CLOSED
14:42:05 - Tenant platinum-1 fully recovered
15:00:00 - Postmortem initiated using Five Whys analysis

Total Impact:
- Detection: 40 seconds (below 60-second SLA)
- Isolation: 55 seconds (below 60-second SLA)
- Recovery: 12 minutes
- Affected tenants: 1 out of 50 (2% blast radius)
- Cost impact: ₹15 lakh (vs ₹5.5 crore platform outage)

## Tenant Tier Examples

Platinum Tier (₹2 crore+ contracts):
- Enterprise Corp: 10,000 employees, 99.99% SLA, 24/7 support
- Global Industries: 5,000 employees, 99.99% SLA, dedicated account manager
- Mega Systems: 8,000 employees, 99.99% SLA, custom integrations

Gold Tier (₹50 lakh+ contracts):
- Mid-Market Inc: 1,000 employees, 99.9% SLA, business hours support
- Regional Services: 800 employees, 99.9% SLA, priority support
- Growth Startup: 500 employees, 99.9% SLA, standard integrations

Silver Tier (₹10 lakh+ contracts):
- Small Business Co: 100 employees, 99% SLA, email support
- Tech Agency: 50 employees, 99% SLA, community support
- Boutique Firm: 25 employees, 99% SLA, self-service portal

Bronze Tier (<₹10 lakh contracts):
- Startup Alpha: 10 employees, best-effort SLA, free trial
- Beta Company: 5 employees, best-effort SLA, basic features
- Gamma Labs: 3 employees, best-effort SLA, proof-of-concept

## Circuit Breaker State Examples

CLOSED State (Normal Operation):
- Failure count: 0
- Error rate: 5% (below 50% threshold)
- All queries pass through normally
- No isolation or degradation
- Full platform access

OPEN State (Isolated):
- Failure count: 5+ consecutive failures
- Error rate: 85% (above 50% threshold)
- All queries blocked immediately
- Tenant isolated from platform
- Fast-fail response (no resource consumption)

HALF_OPEN State (Testing Recovery):
- Timeout expired (60 seconds since OPEN)
- Allowing limited test queries
- Monitoring for success or failure
- Success → transition to CLOSED
- Failure → transition back to OPEN

## Five Whys Analysis Example

Incident: Database connection pool exhaustion

Why #1: Why did the platform go down?
Answer: Database connection pool exhausted (100/100 connections used)

Why #2: Why did the connection pool exhaust?
Answer: One tenant (tenant-A) made 1000 concurrent queries

Why #3: Why did tenant-A make 1000 concurrent queries?
Answer: No per-tenant connection limit configured

Why #4: Why no per-tenant connection limit?
Answer: Multi-tenancy isolation was deprioritized for feature work

Why #5: Why was isolation deprioritized?
Answer: No incident history to justify cost (ROOT CAUSE)

Action Items (Blameless):
1. Implement per-tenant connection limits (max 10 connections per tenant)
2. Add connection pool monitoring to Prometheus
3. Create runbook for connection pool exhaustion
4. Review all shared resources for similar risks

## Prometheus Query Examples

# Discover all active tenants
GET /api/v1/label/tenant_id/values
Response: ["tenant-A", "tenant-B", "tenant-C", ...]

# Query total queries for tenant-A
GET /api/v1/query?query=sum(rate(rag_queries_total{tenant_id="tenant-A"}[5m]))
Response: {"status": "success", "data": {"result": [{"value": [timestamp, "1000"]}]}}

# Query error queries for tenant-A
GET /api/v1/query?query=sum(rate(rag_queries_errors{tenant_id="tenant-A"}[5m]))
Response: {"status": "success", "data": {"result": [{"value": [timestamp, "600"]}]}}

# Calculate error rate
error_rate = error_queries / total_queries
error_rate = 600 / 1000 = 0.60 (60%)

# Compare against threshold
if error_rate >= 0.50:
    trigger_circuit_breaker()

## Cost Impact Analysis

Platform-Wide Outage (No Containment):
- Affected tenants: 50
- Downtime: 3 hours
- Cost per tenant per hour: ₹36,600 (avg across all tiers)
- Total cost: 50 × 3 × ₹36,600 = ₹5.5 crore

Single-Tenant Incident (With Containment):
- Affected tenants: 1
- Downtime: 3 hours (for that tenant only)
- Cost per tenant per hour: ₹5,000 (Bronze tier)
- Total cost: 1 × 3 × ₹5,000 = ₹15 lakh

Savings: ₹5.5 crore - ₹15 lakh = ₹5.35 crore (36x cost reduction)

ROI Calculation:
- Infrastructure cost: ₹75K/month (hybrid setup)
- First prevented outage: ₹5.5 crore saved
- Payback period: 73 months of infrastructure costs covered by first incident

## Notification Message Examples

PagerDuty Alert:
Subject: [P0] INC-20250115-143000 - Platinum Tenant Down
Body: Tenant platinum-1 isolated due to 85% error rate. Circuit breaker OPEN. Other 49 tenants operational. War room initiated.

Slack Message:
:rotating_light: **P0 INCIDENT** :rotating_light:
**Incident ID**: INC-20250115-143000
**Priority**: P0 (Critical)
**Affected Tenants**: tenant-platinum-1
**Tier**: PLATINUM
**Error Rate**: 85%
**Status**: Isolated (Circuit Breaker OPEN)
**Other Tenants**: 49/50 operational
**Est. Cost**: ₹50K/hour
**Actions**: War room #incident-20250115 | Runbook: http://wiki/p0-runbook

Email to Tenant Admin:
Subject: Service Degradation Notification - Tenant platinum-1
Dear Admin,

We detected elevated error rates (85%) on your tenant (platinum-1) at 14:30:40 IST.
Our automated system isolated your tenant to protect other customers.
Our ops team is investigating and will contact you within 15 minutes (P0 SLA).

Current Status: Isolated (Circuit Breaker OPEN)
Estimated Resolution: 30-60 minutes
Support: support@example.com | +91-80-1234-5678

We apologize for the inconvenience.

## Sample Runbook (P0 Platinum Tenant)

1. War Room Setup (0-5 min)
   - Create Slack channel: #incident-YYYYMMDD
   - Page CTO and VP Engineering
   - Join Zoom bridge: http://zoom/warroom

2. Initial Assessment (5-15 min)
   - Check circuit breaker status: GET /circuit-breakers
   - Review Prometheus dashboards: http://grafana/blast-radius
   - Identify root cause from logs: http://elk/tenant-platinum-1
   - Estimate impact and ETA

3. Mitigation (15-30 min)
   - Roll back recent deployments if applicable
   - Kill problematic queries if database issue
   - Scale resources if capacity issue
   - Monitor recovery via HALF_OPEN state

4. Recovery (30-60 min)
   - Verify error rate drops below 50%
   - Confirm circuit breaker transitions to CLOSED
   - Test tenant queries manually
   - Monitor for 15 minutes post-recovery

5. Postmortem (within 24 hours)
   - Schedule postmortem meeting (blameless)
   - Complete Five Whys analysis
   - Identify action items with owners and deadlines
   - Update runbook with lessons learned

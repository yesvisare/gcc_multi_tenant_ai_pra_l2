{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "learning-arc",
   "metadata": {},
   "source": [
    "# L3 M13.1: Multi-Tenant Performance Patterns\n",
    "\n",
    "## Learning Arc\n",
    "\n",
    "**Purpose:** Learn how to architect performance isolation in multi-tenant RAG systems, preventing the noisy neighbor problem where one tenant's traffic spike degrades everyone else's experience.\n",
    "\n",
    "**Concepts Covered:**\n",
    "- Tenant-scoped Redis caching with namespace isolation\n",
    "- Performance tier enforcement (Platinum/Gold/Silver SLAs)\n",
    "- Query optimization strategies with adaptive TTLs\n",
    "- Scoped cache invalidation\n",
    "- Hot tenant detection and resource management\n",
    "- Multi-tenant monitoring and metrics\n",
    "- Production failure scenarios and debugging\n",
    "\n",
    "**After Completing This Notebook:**\n",
    "- You will understand how namespace isolation prevents cross-tenant cache collisions\n",
    "- You can implement performance tier SLAs with hard timeouts\n",
    "- You will recognize hot tenant patterns and implement throttling\n",
    "- You can design cache invalidation that doesn't affect all tenants\n",
    "- You will be able to monitor and debug multi-tenant performance issues\n",
    "\n",
    "**Context in Track L3.M13:**\n",
    "This module builds on M11-M12 (multi-tenant architecture foundations) and prepares you for M13.2 (auto-scaling). You'll add performance guarantees to the multi-tenant platform you've been building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-info",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "This notebook runs in OFFLINE mode by default (no Redis required). Set `REDIS_ENABLED=true` in your `.env` file to enable actual caching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environment-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import json\n",
    "from typing import Dict, Any\n",
    "\n",
    "# Add src to path for imports\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.insert(0, '../src')\n",
    "\n",
    "# OFFLINE mode for L3 consistency\n",
    "OFFLINE = os.getenv(\"OFFLINE\", \"true\").lower() == \"true\"\n",
    "REDIS_ENABLED = os.getenv(\"REDIS_ENABLED\", \"false\").lower() == \"true\"\n",
    "\n",
    "if OFFLINE or not REDIS_ENABLED:\n",
    "    print(\"âš ï¸ Running in OFFLINE/REDIS_DISABLED mode\")\n",
    "    print(\"   â†' External Redis operations will be skipped\")\n",
    "    print(\"   â†' Set REDIS_ENABLED=true in .env to enable caching\")\n",
    "else:\n",
    "    print(\"âœ" Online mode - Redis caching enabled\")\n",
    "\n",
    "# Import our modules\n",
    "from l3_m13_performance_patterns import (\n",
    "    TenantCache,\n",
    "    PerformanceTier,\n",
    "    PerformanceTierEnforcer,\n",
    "    get_tenant_tier_config,\n",
    "    generate_query_hash,\n",
    "    execute_cached_query,\n",
    "    mock_vector_query\n",
    ")\n",
    "\n",
    "print(\"\\nâœ" Imports successful\")\n",
    "print(f\"   OFFLINE: {OFFLINE}\")\n",
    "print(f\"   REDIS_ENABLED: {REDIS_ENABLED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-1",
   "metadata": {},
   "source": [
    "## 1. Understanding Performance Isolation\n",
    "\n",
    "### The Noisy Neighbor Problem\n",
    "\n",
    "In multi-tenant systems, **performance isolation** means Tenant A's traffic spike cannot degrade Tenant B's latency. This is different from **data isolation** (which you implemented in M11-M12).\n",
    "\n",
    "**Without isolation:**\n",
    "- Tenant A spikes from 100 → 10,000 queries/hour\n",
    "- Shared Redis cache fills up\n",
    "- Redis evicts entries based on LRU (Least Recently Used)\n",
    "- Tenant B's cache entries get evicted\n",
    "- Tenant B now experiences cache misses → higher latency\n",
    "- Tenant A's success becomes Tenant B's outage\n",
    "\n",
    "**With namespace isolation:**\n",
    "- Tenant A fills their namespace: `cache:tenant_a:*`\n",
    "- Tenant B's namespace remains untouched: `cache:tenant_b:*`\n",
    "- Tenant B's cache hit rate stays at 80%+\n",
    "- Tenant A's spike is isolated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-2",
   "metadata": {},
   "source": [
    "## 2. Performance Tiers Configuration\n",
    "\n",
    "Multi-tenant platforms typically offer tiered SLAs:\n",
    "- **Platinum:** <200ms, 1-hour cache, 1000 QPS, ₹15K/month\n",
    "- **Gold:** <500ms, 30-min cache, 500 QPS, ₹8K/month\n",
    "- **Silver:** <1s, 15-min cache, 200 QPS, ₹5K/month\n",
    "\n",
    "Let's examine the tier configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tier-config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine tier configurations\n",
    "tiers = ['platinum', 'gold', 'silver']\n",
    "\n",
    "print(\"Performance Tier Configurations:\\n\")\n",
    "print(f\"{'Tier':<10} {'Timeout':<12} {'Cache TTL':<12} {'Max QPS':<10} {'Quota (GB)':<12}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for tier in tiers:\n",
    "    config = get_tenant_tier_config(tier)\n",
    "    print(f\"{tier.capitalize():<10} {config.timeout_ms}ms{'':<8} {config.cache_ttl}s{'':<7} {config.max_qps:<10} {config.cache_quota_gb:<12}\")\n",
    "\n",
    "# Expected: Three tiers with different SLA parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-3",
   "metadata": {},
   "source": [
    "## 3. Tenant Cache with Namespace Isolation\n",
    "\n",
    "The `TenantCache` class wraps Redis operations with automatic namespace prefixing. Every cache key is prefixed with `cache:tenant_id:`, creating logical isolation on shared infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tenant-cache-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create caches for two different tenants\n",
    "cache_sales = TenantCache(\n",
    "    tenant_id=\"tenant_sales\",\n",
    "    tier=\"platinum\",\n",
    "    redis_client=None,  # None = offline mode\n",
    "    offline=True\n",
    ")\n",
    "\n",
    "cache_hr = TenantCache(\n",
    "    tenant_id=\"tenant_hr\",\n",
    "    tier=\"gold\",\n",
    "    redis_client=None,\n",
    "    offline=True\n",
    ")\n",
    "\n",
    "print(\"Tenant Caches Created:\")\n",
    "print(f\"  Sales: {cache_sales.prefix}*\")\n",
    "print(f\"  HR: {cache_hr.prefix}*\")\n",
    "print(f\"\\nNotice different prefixes → namespace isolation\")\n",
    "\n",
    "# Expected: Different prefixes (cache:tenant_sales: vs cache:tenant_hr:)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-4",
   "metadata": {},
   "source": [
    "## 4. Query Hash Generation with Tenant Isolation\n",
    "\n",
    "Query hashes include the tenant_id to ensure that even identical queries from different tenants get different cache keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "query-hash-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same query for different tenants\n",
    "query = \"What is our Q4 performance?\"\n",
    "\n",
    "hash_sales = generate_query_hash(query, \"tenant_sales\")\n",
    "hash_hr = generate_query_hash(query, \"tenant_hr\")\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(f\"Sales hash: {hash_sales}\")\n",
    "print(f\"HR hash: {hash_hr}\")\n",
    "print(f\"\\nDifferent hashes? {hash_sales != hash_hr}\")\n",
    "print(\"\\nThis prevents cache collisions between tenants with identical queries\")\n",
    "\n",
    "# Expected: Different hashes despite same query text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-5",
   "metadata": {},
   "source": [
    "## 5. Performance Tier Enforcement with Timeouts\n",
    "\n",
    "The `PerformanceTierEnforcer` ensures that queries respect tier-specific SLA timeouts. Platinum queries timeout at 200ms, even if they're not done processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tier-enforcement-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create enforcer\n",
    "enforcer = PerformanceTierEnforcer()\n",
    "\n",
    "# Define a slow query (simulates complex vector search)\n",
    "async def slow_query(duration_sec: float):\n",
    "    \"\"\"Simulate a query that takes 'duration_sec' seconds\"\"\"\n",
    "    await asyncio.sleep(duration_sec)\n",
    "    return {\"result\": f\"Completed in {duration_sec}s\"}\n",
    "\n",
    "# Test 1: Fast query within platinum timeout (200ms)\n",
    "print(\"Test 1: Fast query (100ms) with Platinum tier (200ms timeout)\")\n",
    "try:\n",
    "    result = await enforcer.enforce_timeout(\n",
    "        \"tenant_sales\",\n",
    "        \"platinum\",\n",
    "        slow_query,\n",
    "        0.1  # 100ms\n",
    "    )\n",
    "    print(f\"âœ" Success: {result}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed: {e}\\n\")\n",
    "\n",
    "# Test 2: Slow query exceeds platinum timeout\n",
    "print(\"Test 2: Slow query (300ms) with Platinum tier (200ms timeout)\")\n",
    "try:\n",
    "    result = await enforcer.enforce_timeout(\n",
    "        \"tenant_sales\",\n",
    "        \"platinum\",\n",
    "        slow_query,\n",
    "        0.3  # 300ms - exceeds 200ms platinum timeout\n",
    "    )\n",
    "    print(f\"âœ" Success: {result}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Timeout enforced: {type(e).__name__}\\n\")\n",
    "\n",
    "# Test 3: Same slow query with Silver tier (1000ms timeout)\n",
    "print(\"Test 3: Slow query (300ms) with Silver tier (1000ms timeout)\")\n",
    "try:\n",
    "    result = await enforcer.enforce_timeout(\n",
    "        \"tenant_support\",\n",
    "        \"silver\",\n",
    "        slow_query,\n",
    "        0.3  # 300ms - within 1000ms silver timeout\n",
    "    )\n",
    "    print(f\"âœ" Success: {result}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed: {e}\\n\")\n",
    "\n",
    "print(\"Key Insight: Same query succeeds/fails based on tenant tier\")\n",
    "\n",
    "# Expected: Test 1 succeeds, Test 2 times out, Test 3 succeeds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-6",
   "metadata": {},
   "source": [
    "## 6. Complete Query Flow with Caching\n",
    "\n",
    "The `execute_cached_query` function combines caching, tier enforcement, and query execution into a single flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-flow-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute a query with caching (offline mode)\n",
    "query = \"What were our Q4 sales numbers?\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "\n",
    "result = await execute_cached_query(\n",
    "    query=query,\n",
    "    tenant_id=\"tenant_sales\",\n",
    "    tier=\"platinum\",\n",
    "    redis_client=None,\n",
    "    query_executor=mock_vector_query,\n",
    "    offline=True\n",
    ")\n",
    "\n",
    "print(\"Result:\")\n",
    "print(json.dumps(result, indent=2))\n",
    "print(f\"\\nCached: {result['cached']}\")\n",
    "print(f\"Source: {result['source']}\")\n",
    "print(\"\\nNote: In offline mode, queries always miss cache and execute directly\")\n",
    "\n",
    "# Expected: cached=False, source='query' (because OFFLINE=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-7",
   "metadata": {},
   "source": [
    "## 7. Cache Metrics Tracking\n",
    "\n",
    "Monitor per-tenant cache performance: hit rate, cache size, key count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metrics-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cache and simulate operations\n",
    "cache = TenantCache(\"tenant_demo\", \"gold\", None, offline=True)\n",
    "\n",
    "# Simulate cache operations (offline - all misses)\n",
    "for i in range(10):\n",
    "    await cache.get(f\"query_{i}\")\n",
    "\n",
    "# Get metrics\n",
    "metrics = await cache.get_metrics()\n",
    "\n",
    "print(\"Cache Metrics:\")\n",
    "print(f\"  Tenant: {metrics.tenant_id}\")\n",
    "print(f\"  Hits: {metrics.hits}\")\n",
    "print(f\"  Misses: {metrics.misses}\")\n",
    "print(f\"  Hit Rate: {metrics.hit_rate:.1%}\")\n",
    "print(f\"  Cache Size: {metrics.size_gb:.2f} GB\")\n",
    "print(f\"  Key Count: {metrics.key_count}\")\n",
    "\n",
    "# Expected: All misses (offline mode), 0% hit rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-8",
   "metadata": {},
   "source": [
    "## 8. Namespace Isolation Demonstration\n",
    "\n",
    "Show that different tenants get different cache keys even with identical queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "namespace-isolation-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same query for three tenants\n",
    "query = \"Show me the dashboard\"\n",
    "\n",
    "tenants = [\"tenant_a\", \"tenant_b\", \"tenant_c\"]\n",
    "\n",
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Cache Keys by Tenant:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for tenant in tenants:\n",
    "    cache = TenantCache(tenant, \"gold\", None, offline=True)\n",
    "    query_hash = generate_query_hash(query, tenant)\n",
    "    full_key = cache._make_key(query_hash)\n",
    "    print(f\"{tenant:<15} â†' {full_key}\")\n",
    "\n",
    "print(\"\\nâœ" Each tenant gets a unique cache key\")\n",
    "print(\"   No collision, no cross-tenant data leakage\")\n",
    "\n",
    "# Expected: Three different cache keys with different prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-9",
   "metadata": {},
   "source": [
    "## 9. Production Failure Scenarios\n",
    "\n",
    "Let's examine common failures from production multi-tenant systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failure-1",
   "metadata": {},
   "source": [
    "### Failure #1: Namespace Collision\n",
    "\n",
    "**Symptom:** Tenant A gets Tenant B's results (rare but catastrophic)\n",
    "\n",
    "**Cause:** Developer forgot TenantCache wrapper, used direct Redis access\n",
    "\n",
    "**Fix:** Always use TenantCache wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failure-1-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAD: Direct Redis access (no namespace)\n",
    "# cache_key = hash(query)  # âŒ WRONG\n",
    "# redis.get(cache_key)     # âŒ Can collide across tenants\n",
    "\n",
    "# GOOD: Use TenantCache wrapper\n",
    "cache = TenantCache(\"tenant_a\", \"gold\", None, offline=True)\n",
    "# cache.get(hash(query))  # âœ" Automatically namespaced\n",
    "\n",
    "print(\"âœ" Always use TenantCache wrapper\")\n",
    "print(\"   It automatically adds namespace prefix\")\n",
    "print(\"   Prevents cross-tenant collisions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "failure-2",
   "metadata": {},
   "source": [
    "### Failure #3: Timeout Too Loose\n",
    "\n",
    "**Symptom:** Platinum tenants complain about slow queries (800ms) despite 200ms SLA\n",
    "\n",
    "**Cause:** Timeout set to 2 seconds (too loose), doesn't enforce SLA\n",
    "\n",
    "**Fix:** Timeout must match tier SLA exactly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failure-3-demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate timeout enforcement\n",
    "enforcer = PerformanceTierEnforcer()\n",
    "\n",
    "async def query_800ms():\n",
    "    await asyncio.sleep(0.8)\n",
    "    return \"result\"\n",
    "\n",
    "# With proper timeout (200ms for platinum)\n",
    "print(\"Query takes 800ms, Platinum timeout is 200ms:\")\n",
    "try:\n",
    "    await enforcer.enforce_timeout(\"tenant_p\", \"platinum\", query_800ms)\n",
    "    print(\"âœ" Query succeeded\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Timeout enforced: {type(e).__name__}\")\n",
    "    print(\"   SLA protected - query killed at 200ms\")\n",
    "\n",
    "# Expected: Timeout after 200ms (SLA enforced)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "section-10",
   "metadata": {},
   "source": [
    "## 10. Key Takeaways\n",
    "\n",
    "### What You Learned\n",
    "\n",
    "1. **Namespace Isolation:** `cache:tenant_id:key` pattern prevents cross-tenant collisions\n",
    "2. **Tier Enforcement:** Hard timeouts ensure Platinum tenants get <200ms latency\n",
    "3. **Scoped Operations:** Cache invalidation affects only one tenant\n",
    "4. **Metrics Tracking:** Monitor hit rate, cache size, latency per tenant\n",
    "5. **Production Failures:** Most issues come from forgetting to scope by tenant_id\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "- âœ… All Redis access through TenantCache wrapper\n",
    "- âœ… Timeouts match tier SLAs exactly\n",
    "- âœ… Per-tenant quotas enforced (prevent eviction cascade)\n",
    "- âœ… Cache invalidation is tenant-scoped (never use FLUSHDB)\n",
    "- âœ… Monitoring tracks per-tenant metrics\n",
    "- âœ… Load testing proves isolation (Tenant A spike → Tenant B stable)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- **M13.2:** Auto-scaling and load balancing\n",
    "- **M13.3:** Cost optimization strategies\n",
    "- **M13.4:** Capacity planning and forecasting\n",
    "\n",
    "### Resources\n",
    "\n",
    "- Full code: `src/l3_m13_performance_patterns/__init__.py`\n",
    "- API: `app.py`\n",
    "- Tests: `tests/test_m13_performance_patterns.py`\n",
    "- README: Complete documentation and decision card"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
